# Generative Adversarial Networks Compression
The final project for Columbia University COMS 6998 012 Practical Deep Learning Systems Performance

This project aims at finding an approach for Generative Adversarial Networks (GANs) compression.

We use knowledge distillation method to solve this problem by adding a pixelwise constraint on the output of the student generator and teacher generator.

![image](https://user-images.githubusercontent.com/120711627/208582366-a4816226-7f8f-479a-b670-89bab553a9e0.png)

To use this repository, you can open the jupyter notebooks directly to see the result of each conditional GAN training w or w/o knowledge distillation from a larger model.
